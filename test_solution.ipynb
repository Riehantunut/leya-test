{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of solution\n",
    "\n",
    "My tech stack is LlamaIndex, BM25, OpenAI (gpt-4o-mini throughout).   \n",
    "\n",
    "I put most focus on the search engine, as the LLM only can answer as well as the data it is given. Therefore hybrid search has been implemented to both use contextual info (embeddings) and also search on keywords (BM25). The User question is also rewritten before search, to make sure that the wording doesn't negatively affect search.    \n",
    "\n",
    "#### The steps are:\n",
    "\n",
    "1. Chunking  \n",
    "1.1. Text is chunked by sentences\n",
    "\n",
    "2. Search engine  \n",
    "2.1. User question is rewritten (by GPT-4o-mini) to remove superfluous words -> improving search  \n",
    "2.2 Hybrid search is used, with equal weight on both BM25 (keyword search) and vector search (text embeddings). There is a limitation on number of search hits to not go over token limit.\n",
    "\n",
    "3. Answering  \n",
    "3.1. GPT-4o-mini is fed search results and is instructed to reason and then answer. There is no strict limitation on output format, _focus is to reason/think before answering_.  \n",
    "3.2. A second call to GPT-4o-mini is used to re-format answer to suit the output format.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to test the solution\n",
    "\n",
    "1. Set up environment (I used Python 3.9)\n",
    "2. Run through the example below\n",
    "3. Look through explanation of solution\n",
    "\n",
    "\n",
    "#### 1.0. Set the OPENAI_API_KEY env variable and install requirements.txt\n",
    "\n",
    "Sometimes running these commands does not work in Jupyter notebooks, you may need to run the commands below in your terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export OPENAI_API_KEY=\"your_api_key_here\"\n",
    "# Note that you may have to do this in the terminal, Jupyter notebooks are not water-tight regarding setting env vars in code-cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aiohappyeyeballs==2.4.6 (from -r requirements.txt (line 1))\n",
      "  Using cached aiohappyeyeballs-2.4.6-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiohttp==3.11.13 (from -r requirements.txt (line 2))\n",
      "  Downloading aiohttp-3.11.13-cp310-cp310-macosx_10_9_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting aiosignal==1.3.2 (from -r requirements.txt (line 3))\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting annotated-types==0.7.0 (from -r requirements.txt (line 4))\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting anyio==4.8.0 (from -r requirements.txt (line 5))\n",
      "  Using cached anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: appnope==0.1.4 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (0.1.4)\n",
      "Requirement already satisfied: asttokens==3.0.0 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (3.0.0)\n",
      "Collecting async-timeout==5.0.1 (from -r requirements.txt (line 8))\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs==25.1.0 (from -r requirements.txt (line 9))\n",
      "  Using cached attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting backcall==0.2.0 (from -r requirements.txt (line 10))\n",
      "  Using cached backcall-0.2.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting beautifulsoup4==4.13.3 (from -r requirements.txt (line 11))\n",
      "  Using cached beautifulsoup4-4.13.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bm25s==0.2.7.post1 (from -r requirements.txt (line 12))\n",
      "  Using cached bm25s-0.2.7.post1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting certifi==2025.1.31 (from -r requirements.txt (line 13))\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting charset-normalizer==3.4.1 (from -r requirements.txt (line 14))\n",
      "  Downloading charset_normalizer-3.4.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (35 kB)\n",
      "Collecting click==8.1.8 (from -r requirements.txt (line 15))\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: comm==0.2.2 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (0.2.2)\n",
      "Collecting contourpy==1.3.0 (from -r requirements.txt (line 17))\n",
      "  Downloading contourpy-1.3.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler==0.12.1 (from -r requirements.txt (line 18))\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting dataclasses-json==0.6.7 (from -r requirements.txt (line 19))\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: debugpy==1.8.12 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 20)) (1.8.12)\n",
      "Requirement already satisfied: decorator==5.2.1 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 21)) (5.2.1)\n",
      "Collecting Deprecated==1.2.18 (from -r requirements.txt (line 22))\n",
      "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting dirtyjson==1.0.8 (from -r requirements.txt (line 23))\n",
      "  Using cached dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting distro==1.9.0 (from -r requirements.txt (line 24))\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting eval_type_backport==0.2.2 (from -r requirements.txt (line 25))\n",
      "  Using cached eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: exceptiongroup==1.2.2 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 26)) (1.2.2)\n",
      "Collecting executing==2.2.0 (from -r requirements.txt (line 27))\n",
      "  Using cached executing-2.2.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting filetype==1.2.0 (from -r requirements.txt (line 28))\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting fonttools==4.56.0 (from -r requirements.txt (line 29))\n",
      "  Downloading fonttools-4.56.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (101 kB)\n",
      "Collecting frozenlist==1.5.0 (from -r requirements.txt (line 30))\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (13 kB)\n",
      "Collecting fsspec==2025.2.0 (from -r requirements.txt (line 31))\n",
      "  Using cached fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting greenlet==3.1.1 (from -r requirements.txt (line 32))\n",
      "  Downloading greenlet-3.1.1-cp310-cp310-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Collecting h11==0.14.0 (from -r requirements.txt (line 33))\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting httpcore==1.0.7 (from -r requirements.txt (line 34))\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting httpx==0.28.1 (from -r requirements.txt (line 35))\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting idna==3.10 (from -r requirements.txt (line 36))\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: importlib_metadata==8.6.1 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 37)) (8.6.1)\n",
      "Collecting importlib_resources==6.5.2 (from -r requirements.txt (line 38))\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: ipykernel==6.29.5 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 39)) (6.29.5)\n",
      "Collecting ipython==8.18.1 (from -r requirements.txt (line 40))\n",
      "  Using cached ipython-8.18.1-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: jedi==0.19.2 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 41)) (0.19.2)\n",
      "Collecting jiter==0.8.2 (from -r requirements.txt (line 42))\n",
      "  Downloading jiter-0.8.2-cp310-cp310-macosx_10_12_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting joblib==1.4.2 (from -r requirements.txt (line 43))\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 44)) (8.6.3)\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 45)) (5.7.2)\n",
      "Collecting kiwisolver==1.4.7 (from -r requirements.txt (line 46))\n",
      "  Downloading kiwisolver-1.4.7-cp310-cp310-macosx_10_9_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting llama-cloud==0.1.13 (from -r requirements.txt (line 47))\n",
      "  Using cached llama_cloud-0.1.13-py3-none-any.whl.metadata (800 bytes)\n",
      "Collecting llama-cloud-services==0.6.3 (from -r requirements.txt (line 48))\n",
      "  Using cached llama_cloud_services-0.6.3-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting llama-index==0.12.22 (from -r requirements.txt (line 49))\n",
      "  Using cached llama_index-0.12.22-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting llama-index-agent-openai==0.4.6 (from -r requirements.txt (line 50))\n",
      "  Using cached llama_index_agent_openai-0.4.6-py3-none-any.whl.metadata (727 bytes)\n",
      "Collecting llama-index-cli==0.4.1 (from -r requirements.txt (line 51))\n",
      "  Using cached llama_index_cli-0.4.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core==0.12.22 (from -r requirements.txt (line 52))\n",
      "  Using cached llama_index_core-0.12.22-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-index-embeddings-openai==0.3.1 (from -r requirements.txt (line 53))\n",
      "  Using cached llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud==0.6.8 (from -r requirements.txt (line 54))\n",
      "  Using cached llama_index_indices_managed_llama_cloud-0.6.8-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting llama-index-llms-openai==0.3.25 (from -r requirements.txt (line 55))\n",
      "  Using cached llama_index_llms_openai-0.3.25-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai==0.4.3 (from -r requirements.txt (line 56))\n",
      "  Using cached llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n",
      "Collecting llama-index-program-openai==0.3.1 (from -r requirements.txt (line 57))\n",
      "  Using cached llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
      "Collecting llama-index-question-gen-openai==0.3.0 (from -r requirements.txt (line 58))\n",
      "  Using cached llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
      "Collecting llama-index-readers-file==0.4.5 (from -r requirements.txt (line 59))\n",
      "  Using cached llama_index_readers_file-0.4.5-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse==0.4.0 (from -r requirements.txt (line 60))\n",
      "  Using cached llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting llama-index-retrievers-bm25==0.5.2 (from -r requirements.txt (line 61))\n",
      "  Using cached llama_index_retrievers_bm25-0.5.2-py3-none-any.whl.metadata (740 bytes)\n",
      "Collecting llama-parse==0.6.2 (from -r requirements.txt (line 62))\n",
      "  Using cached llama_parse-0.6.2-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting marshmallow==3.26.1 (from -r requirements.txt (line 63))\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting matplotlib==3.9.4 (from -r requirements.txt (line 64))\n",
      "  Downloading matplotlib-3.9.4-cp310-cp310-macosx_10_12_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 65)) (0.1.7)\n",
      "Collecting multidict==6.1.0 (from -r requirements.txt (line 66))\n",
      "  Downloading multidict-6.1.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting mypy-extensions==1.0.0 (from -r requirements.txt (line 67))\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting narwhals==1.28.0 (from -r requirements.txt (line 68))\n",
      "  Using cached narwhals-1.28.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 69)) (1.6.0)\n",
      "Collecting networkx==3.2.1 (from -r requirements.txt (line 70))\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting nltk==3.9.1 (from -r requirements.txt (line 71))\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting numpy==2.0.2 (from -r requirements.txt (line 72))\n",
      "  Downloading numpy-2.0.2-cp310-cp310-macosx_14_0_x86_64.whl.metadata (60 kB)\n",
      "Collecting openai==1.65.2 (from -r requirements.txt (line 73))\n",
      "  Using cached openai-1.65.2-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: packaging==24.2 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 74)) (24.2)\n",
      "Collecting pandas==2.2.3 (from -r requirements.txt (line 75))\n",
      "  Downloading pandas-2.2.3-cp310-cp310-macosx_10_9_x86_64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: parso==0.8.4 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 76)) (0.8.4)\n",
      "Requirement already satisfied: pexpect==4.9.0 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 77)) (4.9.0)\n",
      "Requirement already satisfied: pickleshare==0.7.5 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 78)) (0.7.5)\n",
      "Collecting pillow==11.1.0 (from -r requirements.txt (line 79))\n",
      "  Downloading pillow-11.1.0-cp310-cp310-macosx_10_10_x86_64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: platformdirs==4.3.6 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 80)) (4.3.6)\n",
      "Collecting plotly==6.0.0 (from -r requirements.txt (line 81))\n",
      "  Using cached plotly-6.0.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.50 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 82)) (3.0.50)\n",
      "Collecting propcache==0.3.0 (from -r requirements.txt (line 83))\n",
      "  Downloading propcache-0.3.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: psutil==7.0.0 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 84)) (7.0.0)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 85)) (0.7.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 86)) (0.2.3)\n",
      "Collecting pydantic==2.10.6 (from -r requirements.txt (line 87))\n",
      "  Using cached pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting pydantic_core==2.27.2 (from -r requirements.txt (line 88))\n",
      "  Downloading pydantic_core-2.27.2-cp310-cp310-macosx_10_12_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: Pygments==2.19.1 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 89)) (2.19.1)\n",
      "Collecting pyparsing==3.2.1 (from -r requirements.txt (line 90))\n",
      "  Using cached pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting pypdf==5.3.1 (from -r requirements.txt (line 91))\n",
      "  Using cached pypdf-5.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting PyStemmer==2.2.0.3 (from -r requirements.txt (line 92))\n",
      "  Downloading PyStemmer-2.2.0.3-cp310-cp310-macosx_10_9_x86_64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 93)) (2.9.0.post0)\n",
      "Collecting python-dotenv==1.0.1 (from -r requirements.txt (line 94))\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting pytz==2025.1 (from -r requirements.txt (line 95))\n",
      "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting PyYAML==6.0.2 (from -r requirements.txt (line 96))\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-macosx_10_9_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: pyzmq==26.2.1 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 97)) (26.2.1)\n",
      "Collecting rank-bm25==0.2.2 (from -r requirements.txt (line 98))\n",
      "  Using cached rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting regex==2024.11.6 (from -r requirements.txt (line 99))\n",
      "  Downloading regex-2024.11.6-cp310-cp310-macosx_10_9_x86_64.whl.metadata (40 kB)\n",
      "Collecting requests==2.32.3 (from -r requirements.txt (line 100))\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting scipy==1.13.1 (from -r requirements.txt (line 101))\n",
      "  Downloading scipy-1.13.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: six==1.17.0 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 102)) (1.17.0)\n",
      "Collecting sniffio==1.3.1 (from -r requirements.txt (line 103))\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting soupsieve==2.6 (from -r requirements.txt (line 104))\n",
      "  Using cached soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting SQLAlchemy==2.0.38 (from -r requirements.txt (line 105))\n",
      "  Downloading SQLAlchemy-2.0.38-cp310-cp310-macosx_10_9_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: stack-data==0.6.3 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 106)) (0.6.3)\n",
      "Collecting striprtf==0.0.26 (from -r requirements.txt (line 107))\n",
      "  Using cached striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting tenacity==9.0.0 (from -r requirements.txt (line 108))\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting tiktoken==0.9.0 (from -r requirements.txt (line 109))\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-macosx_10_12_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tornado==6.4.2 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 110)) (6.4.2)\n",
      "Collecting tqdm==4.67.1 (from -r requirements.txt (line 111))\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: traitlets==5.14.3 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 112)) (5.14.3)\n",
      "Collecting typing-inspect==0.9.0 (from -r requirements.txt (line 113))\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: typing_extensions==4.12.2 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 114)) (4.12.2)\n",
      "Collecting tzdata==2025.1 (from -r requirements.txt (line 115))\n",
      "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting urllib3==2.3.0 (from -r requirements.txt (line 116))\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 117)) (0.2.13)\n",
      "Collecting wrapt==1.17.2 (from -r requirements.txt (line 118))\n",
      "  Downloading wrapt-1.17.2-cp310-cp310-macosx_10_9_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting yarl==1.18.3 (from -r requirements.txt (line 119))\n",
      "  Downloading yarl-1.18.3-cp310-cp310-macosx_10_9_x86_64.whl.metadata (69 kB)\n",
      "Requirement already satisfied: zipp==3.21.0 in ./.conda/lib/python3.10/site-packages (from -r requirements.txt (line 120)) (3.21.0)\n",
      "Using cached aiohappyeyeballs-2.4.6-py3-none-any.whl (14 kB)\n",
      "Downloading aiohttp-3.11.13-cp310-cp310-macosx_10_9_x86_64.whl (468 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached attrs-25.1.0-py3-none-any.whl (63 kB)\n",
      "Using cached backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n",
      "Using cached bm25s-0.2.7.post1-py3-none-any.whl (53 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp310-cp310-macosx_10_9_universal2.whl (198 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading contourpy-1.3.0-cp310-cp310-macosx_10_9_x86_64.whl (265 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Using cached dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Using cached executing-2.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading fonttools-4.56.0-cp310-cp310-macosx_10_9_x86_64.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.5.0-cp310-cp310-macosx_10_9_x86_64.whl (54 kB)\n",
      "Using cached fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
      "Downloading greenlet-3.1.1-cp310-cp310-macosx_11_0_universal2.whl (271 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Using cached ipython-8.18.1-py3-none-any.whl (808 kB)\n",
      "Downloading jiter-0.8.2-cp310-cp310-macosx_10_12_x86_64.whl (303 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading kiwisolver-1.4.7-cp310-cp310-macosx_10_9_x86_64.whl (65 kB)\n",
      "Using cached llama_cloud-0.1.13-py3-none-any.whl (253 kB)\n",
      "Using cached llama_cloud_services-0.6.3-py3-none-any.whl (28 kB)\n",
      "Using cached llama_index-0.12.22-py3-none-any.whl (7.0 kB)\n",
      "Using cached llama_index_agent_openai-0.4.6-py3-none-any.whl (13 kB)\n",
      "Using cached llama_index_cli-0.4.1-py3-none-any.whl (28 kB)\n",
      "Using cached llama_index_core-0.12.22-py3-none-any.whl (1.6 MB)\n",
      "Using cached llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached llama_index_indices_managed_llama_cloud-0.6.8-py3-none-any.whl (13 kB)\n",
      "Using cached llama_index_llms_openai-0.3.25-py3-none-any.whl (16 kB)\n",
      "Using cached llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
      "Using cached llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
      "Using cached llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
      "Using cached llama_index_readers_file-0.4.5-py3-none-any.whl (39 kB)\n",
      "Using cached llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
      "Using cached llama_index_retrievers_bm25-0.5.2-py3-none-any.whl (3.7 kB)\n",
      "Using cached llama_parse-0.6.2-py3-none-any.whl (4.8 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading matplotlib-3.9.4-cp310-cp310-macosx_10_12_x86_64.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.1.0-cp310-cp310-macosx_10_9_x86_64.whl (29 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached narwhals-1.28.0-py3-none-any.whl (308 kB)\n",
      "Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Downloading numpy-2.0.2-cp310-cp310-macosx_14_0_x86_64.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached openai-1.65.2-py3-none-any.whl (473 kB)\n",
      "Downloading pandas-2.2.3-cp310-cp310-macosx_10_9_x86_64.whl (12.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.1.0-cp310-cp310-macosx_10_10_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached plotly-6.0.0-py3-none-any.whl (14.8 MB)\n",
      "Downloading propcache-0.3.0-cp310-cp310-macosx_10_9_x86_64.whl (45 kB)\n",
      "Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp310-cp310-macosx_10_12_x86_64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Using cached pypdf-5.3.1-py3-none-any.whl (302 kB)\n",
      "Downloading PyStemmer-2.2.0.3-cp310-cp310-macosx_10_9_x86_64.whl (214 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Downloading PyYAML-6.0.2-cp310-cp310-macosx_10_9_x86_64.whl (184 kB)\n",
      "Using cached rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-macosx_10_9_x86_64.whl (287 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading scipy-1.13.1-cp310-cp310-macosx_10_9_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Downloading SQLAlchemy-2.0.38-cp310-cp310-macosx_10_9_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading tiktoken-0.9.0-cp310-cp310-macosx_10_12_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Downloading wrapt-1.17.2-cp310-cp310-macosx_10_9_x86_64.whl (38 kB)\n",
      "Downloading yarl-1.18.3-cp310-cp310-macosx_10_9_x86_64.whl (94 kB)\n",
      "Installing collected packages: striprtf, pytz, PyStemmer, filetype, dirtyjson, backcall, wrapt, urllib3, tzdata, tqdm, tenacity, soupsieve, sniffio, regex, PyYAML, python-dotenv, pypdf, pyparsing, pydantic_core, propcache, pillow, numpy, networkx, narwhals, mypy-extensions, multidict, marshmallow, kiwisolver, joblib, jiter, importlib_resources, idna, h11, greenlet, fsspec, frozenlist, fonttools, executing, eval_type_backport, distro, cycler, click, charset-normalizer, certifi, attrs, async-timeout, annotated-types, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, scipy, requests, rank-bm25, pydantic, plotly, pandas, nltk, httpcore, Deprecated, contourpy, beautifulsoup4, anyio, aiosignal, tiktoken, matplotlib, ipython, httpx, dataclasses-json, bm25s, aiohttp, openai, llama-index-core, llama-cloud, llama-index-retrievers-bm25, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "  Attempting uninstall: executing\n",
      "    Found existing installation: executing 2.1.0\n",
      "    Uninstalling executing-2.1.0:\n",
      "      Successfully uninstalled executing-2.1.0\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 8.33.0\n",
      "    Uninstalling ipython-8.33.0:\n",
      "      Successfully uninstalled ipython-8.33.0\n",
      "Successfully installed Deprecated-1.2.18 PyStemmer-2.2.0.3 PyYAML-6.0.2 SQLAlchemy-2.0.38 aiohappyeyeballs-2.4.6 aiohttp-3.11.13 aiosignal-1.3.2 annotated-types-0.7.0 anyio-4.8.0 async-timeout-5.0.1 attrs-25.1.0 backcall-0.2.0 beautifulsoup4-4.13.3 bm25s-0.2.7.post1 certifi-2025.1.31 charset-normalizer-3.4.1 click-8.1.8 contourpy-1.3.0 cycler-0.12.1 dataclasses-json-0.6.7 dirtyjson-1.0.8 distro-1.9.0 eval_type_backport-0.2.2 executing-2.2.0 filetype-1.2.0 fonttools-4.56.0 frozenlist-1.5.0 fsspec-2025.2.0 greenlet-3.1.1 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 idna-3.10 importlib_resources-6.5.2 ipython-8.18.1 jiter-0.8.2 joblib-1.4.2 kiwisolver-1.4.7 llama-cloud-0.1.13 llama-cloud-services-0.6.3 llama-index-0.12.22 llama-index-agent-openai-0.4.6 llama-index-cli-0.4.1 llama-index-core-0.12.22 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.8 llama-index-llms-openai-0.3.25 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.5 llama-index-readers-llama-parse-0.4.0 llama-index-retrievers-bm25-0.5.2 llama-parse-0.6.2 marshmallow-3.26.1 matplotlib-3.9.4 multidict-6.1.0 mypy-extensions-1.0.0 narwhals-1.28.0 networkx-3.2.1 nltk-3.9.1 numpy-2.0.2 openai-1.65.2 pandas-2.2.3 pillow-11.1.0 plotly-6.0.0 propcache-0.3.0 pydantic-2.10.6 pydantic_core-2.27.2 pyparsing-3.2.1 pypdf-5.3.1 python-dotenv-1.0.1 pytz-2025.1 rank-bm25-0.2.2 regex-2024.11.6 requests-2.32.3 scipy-1.13.1 sniffio-1.3.1 soupsieve-2.6 striprtf-0.0.26 tenacity-9.0.0 tiktoken-0.9.0 tqdm-4.67.1 typing-inspect-0.9.0 tzdata-2025.1 urllib3-2.3.0 wrapt-1.17.2 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Go to Line 3 in \"search_engines.py\" and set your OpenAI API key there as well\n",
    "This may not be a problem for you, but for me the env key set in Jupyter is not read in correctly.\n",
    "\n",
    "#### 2.0. Import code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arashdabiri/miniconda3/envs/leya_test/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# We first import the three classes needed\n",
    "from backend import ColumnDataObj, AnswererObj\n",
    "from search_engines import DocSearch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 First we initialize the knowledge base/search engine with the universe of files we are interested in\n",
    "\n",
    "Embeddings are built of the text (using OpenAI's text-embedding-3-small) & and the BM25 search engine is also initialized - as we are using hybrid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine = DocSearch('./data') # Insert all text into the search engine, we can filter it later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 We define the questions, output formats & files to look through\n",
    "\n",
    "We essentially define the \"column\" and \"row\" of one cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "one_column = ColumnDataObj(\"Are there confidentiality agreements?\", \"Boolean\") # Question & output format, here called a \"column\"\n",
    "\n",
    "# Files to look through, one \"row\"\n",
    "file_list = [\n",
    "    \"AzulSa_20170303_F-1A_EX-10.3_9943903_EX-10.3_Maintenance Agreement1.txt\", \n",
    "    \"AzulSa_20170303_F-1A_EX-10.3_9943903_EX-10.3_Maintenance Agreement2.txt\"\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Call the \"answer\" endpoint, using AnswererObj\n",
    "\n",
    "I left some print statements to make it clearer what is happening under the hood :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_query:  confidentiality agreements existence\n",
      "Number of search hits: 7\n",
      "Unformatted answer:  Thoughts:\n",
      "\n",
      "- The provided sources contain references to \"Confidential Information\" and stipulations regarding its treatment.\n",
      "- There are specific obligations for the \"Receiving Party\" regarding the handling of Confidential Information, indicating that there are confidentiality agreements in place.\n",
      "- Confidential Information must only be disclosed to individuals who need to know it for the purpose of the agreement.\n",
      "- The sources emphasize that the Receiving Party is responsible for ensuring its employees adhere to confidentiality obligations.\n",
      "- Disclosure to third parties requires specific conditions, including prior approval from the Disclosing Party and a signed acknowledgment of confidentiality from those third parties.\n",
      "- There are provisions regarding legal disclosures, which highlight that confidentiality obligations may not apply in certain legal circumstances.\n",
      "- The Confidential Information is acknowledged as the property of the Disclosing Party, with stipulations that it remains protected under copyright laws.\n",
      "- The confidentiality clauses appear to survive the termination of the Agreement for a specified period (five years) after the end date.\n",
      "- Options for arbitration are included, with an emphasis on maintaining confidentiality throughout the arbitration process itself.\n",
      "\n",
      "With these points in mind, it's clear that confidentiality agreements are indeed present. The text outlines various obligations and protections surrounding Confidential Information, indicating that the parties involved are bound by confidentiality provisions within their agreement. \n",
      "\n",
      "**Answer:** Yes, there are confidentiality agreements in place, which establish specific obligations regarding the handling of Confidential Information, including restrictions on disclosure and the responsibilities of the Receiving Party.\n",
      "----------------\n",
      "FINAL ANSWER:  Yes\n"
     ]
    }
   ],
   "source": [
    "answer_endpoint = AnswererObj() # Object which handles all answering is instantiated\n",
    "\n",
    "# The \"answer\" function requires the search engine, list of files to filter by & question/output format info\n",
    "bot_answer = answer_endpoint.answer(search_engine, file_list, one_column)\n",
    "\n",
    "print(\"FINAL ANSWER: \", bot_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some more examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_query:  governing law of contract\n",
      "Number of search hits: 11\n",
      "Unformatted answer:  Sure! Here’s how I’ll approach the question:\n",
      "\n",
      "- The question asks about the \"governing law\" of the contract, which refers to the legal framework under which the contract will be interpreted and enforced.\n",
      "- I need to specifically look for any clauses in the provided text that mention governing law.\n",
      "- In the sources, I see multiple references to various clauses indicating that the agreement has certain legal stipulations regarding its execution and interpretation.\n",
      "- I note that \"Clause 24\" is mentioned, and it indicates there's a specific section that addresses governing law and arbitration.\n",
      "\n",
      "After assessing the excerpts more closely, particularly focusing on results that mention the governing law directly:\n",
      "\n",
      "- In the 24.1 Governing Law section, it’s stated that the agreement shall be governed by and construed in accordance with the laws of the State of New York, U.S.A.\n",
      "- This confirmation comes from a specific reference to Section 5-1401 of the New York General Obligations Law and applies to contracts to be performed within New York, excluding certain sections of law specified.\n",
      "\n",
      "Based on this reasoning:\n",
      "\n",
      "The governing law of the contract is the laws of the State of New York, U.S.A.\n",
      "----------------\n",
      "FINAL ANSWER:  The governing law of the contract is the laws of the State of New York, U.S.A.\n"
     ]
    }
   ],
   "source": [
    "one_column = ColumnDataObj(\"What is the governing law of the contract?\", \"Text\")\n",
    "\n",
    "file_list = [\n",
    "    \"AzulSa_20170303_F-1A_EX-10.3_9943903_EX-10.3_Maintenance Agreement1.txt\", \n",
    "    \"AzulSa_20170303_F-1A_EX-10.3_9943903_EX-10.3_Maintenance Agreement2.txt\"\n",
    "    ]\n",
    "\n",
    "print(\"FINAL ANSWER: \", answer_endpoint.answer(search_engine, file_list, one_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_query:  agreement effective date\n",
      "Number of search hits: 12\n",
      "Unformatted answer:  - The term \"Effective Date\" is mentioned several times in the provided text. It appears to be a critical point that marks the start of the agreement's terms.\n",
      "- The \"Effective Date\" is defined in the preamble of the agreement, but I don't have the exact text of the preamble available in the sources.\n",
      "- There's a section that mentions the term of the agreement begins on the Effective Date and expires based on certain conditions.\n",
      "- The text hints at an important date, which is connected to various actions and obligations that are contingent upon the Effective Date.\n",
      "- There is also a specific mention of the date \"January 9, 2020,\" which appears on the signature page for both parties, likely indicating when the agreement was executed.\n",
      "- The language suggests that once the agreement was executed, that date (January 9, 2020) could be considered the Effective Date unless stated otherwise in the preamble.\n",
      "\n",
      "Now to answer the question:\n",
      "\n",
      "The agreement went into force on January 9, 2020.\n",
      "----------------\n",
      "FINAL ANSWER:  2020-01-09\n"
     ]
    }
   ],
   "source": [
    "one_column = ColumnDataObj(\"What is the date when the agreement went into force?\", \"Date\")\n",
    "\n",
    "file_list = [\n",
    "    \"PhasebioPharmaceuticalsInc_20200330_10-K_EX-10.21_12086810_EX-10.21_Development Agreement.txt\"\n",
    "    ]\n",
    "\n",
    "print(\"FINAL ANSWER: \", answer_endpoint.answer(search_engine, file_list, one_column))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leya_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
